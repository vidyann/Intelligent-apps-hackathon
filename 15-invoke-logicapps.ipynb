{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(line):\n",
    "    \"\"\"Process a single line from the stream.\"\"\"\n",
    "    # print(\"line:\",line)\n",
    "    if line.startswith('data: '):\n",
    "        # Extract JSON data following 'data: '\n",
    "        json_data = line[len('data: '):]\n",
    "        try:\n",
    "            data = json.loads(json_data)\n",
    "            if \"event\" in data:\n",
    "                handle_event(data)\n",
    "            elif \"content\" in data:\n",
    "                # If there is immediate content to print\n",
    "                print(data[\"content\"], end=\"\", flush=True)\n",
    "            elif \"steps\" in data:\n",
    "                print(data[\"steps\"])\n",
    "            elif \"output\" in data:\n",
    "                print(data[\"output\"])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decoding error: {e}\")\n",
    "    elif line.startswith('event: '):\n",
    "        pass\n",
    "    elif \": ping\" in line:\n",
    "        pass\n",
    "    else:\n",
    "        print(line)\n",
    "\n",
    "def handle_event(event):\n",
    "    \"\"\"Handles specific events, adjusting output based on event type.\"\"\"\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\" and event[\"name\"] == \"AgentExecutor\":\n",
    "        print(f\"Starting agent: {event['name']}\")\n",
    "    elif kind == \"on_chain_end\" and event[\"name\"] == \"AgentExecutor\":\n",
    "        print(\"\\n--\")\n",
    "        print(f\"Done agent: {event['name']}\")\n",
    "    elif kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"][\"content\"]\n",
    "        if content:  # Ensure content is not None or empty\n",
    "            print(content, end=\"\", flush=True)\n",
    "    elif kind == \"on_tool_start\":\n",
    "        # Assuming event['data'].get('input') is a dictionary\n",
    "        tool_inputs = event['data'].get('input')\n",
    "        if isinstance(tool_inputs, dict):\n",
    "            # Joining the dictionary into a string format key: 'value'\n",
    "            inputs_str = \", \".join(f\"'{v}'\" for k, v in tool_inputs.items())\n",
    "        else:\n",
    "            # Fallback if it's not a dictionary or in an unexpected format\n",
    "            inputs_str = str(tool_inputs)\n",
    "        print(f\"Starting tool: {event['name']} with input: {inputs_str}\")\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\\n--\")\n",
    "\n",
    "    \n",
    "def consume_api(url, payload):\n",
    "    \"\"\"Uses requests POST to talkt to the FastAPI backend, supports streaming\"\"\"\n",
    "    \n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    with requests.post(url, json=payload, headers=headers, stream=True) as response:\n",
    "        try:\n",
    "            response.raise_for_status()  # Raises a HTTPError if the response is not 200\n",
    "            \n",
    "            for line in response.iter_lines():\n",
    "                if line:  # Check if the line is not empty\n",
    "                    decoded_line = line.decode('utf-8')\n",
    "                    process_line(decoded_line)\n",
    "                    \n",
    "                    \n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f\"HTTP Error: {err}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the description of the image provided:\n",
      "- The image is a diagram representing an \"Enterprise AI Platform\" with various components listed in a structured manner.\n",
      "- The diagram consists of multiple layers or sections each containing different elements, which are connected in a hierarchical fashion:\n",
      "  - **Digital Channels Apps** and **Admin Portal**: These are placed at the top of the diagram, indicating they may be the front-end components or interfaces.\n",
      "  \n",
      "  - **AI Gateway**: Just below these components, mentions functionalities such as \"Load Balancing AI endpoints\", \"Token based Monitoring\", and \"Rate Limiting\".\n",
      "  \n",
      "  - **Orchestration Layer**: This lies in the center of the diagram and includes processes like \"Grounding, Meta-Prompt, Response Filtering, Streaming, Intent Recognition\" on one side, and \"Agentric AI System (Conversable agents)\" on the other side.\n",
      "  \n",
      "  - **AI Search**, **AI Service**, and **Bot Framework**: These are listed below the Orchestration Layer with the AI Search detailing \"Indexing, Semantic Ranking\", AI Service detailing \"TTS (Text to Speech), STT (Speech to Text), DI (Digital Interface), Avatar\", and the Bot Framework detailing \"Action Based Workflow\".\n",
      "  \n",
      "  - **LLM / SLM (Managed, Self-Hosted)**: Situated beside the Bot Framework, it relates to the managing and hosting of services with a note \"LLM Ops (Flow, Test Cases)\".\n",
      "  \n",
      "  - **Store**: At the bottom left of the diagram are three types of data storage or databases: \"Vector Store\", \"No SQL\" (mentioned with \"chat history, user profile\"), and \"RDBMS\" (Relational Database Management System) labeled as \"LOB Data Store\".\n",
      "  \n",
      "On the far right of the diagram, there are additional components:\n",
      "  - **AI Studio** and **Playground / Sandbox**: Possibly areas for development and testing AI systems, denoted with graphical elements symbolizing playing or experimentation.\n",
      "  \n",
      "  - **AI Governance**: Labeled \"Responsible AI\", which may indicate an emphasis on ethical and responsible development and use of AI within the platform.\n",
      "Overall, the image represents a conceptual or architectural overview of an enterprise-level AI platform, indicating how various components and services may interact within such a system.\n"
     ]
    }
   ],
   "source": [
    "payload = {'filepath': 'https://stgdatamumhack.blob.core.windows.net/docs/AIAPPS.png?sp=r&st=2024-09-22T13:53:25Z&se=2024-10-30T21:53:25Z&spr=https&sv=2022-11-02&sr=b&sig=HbY0MkeDKhEKvWitmUi0dY9CvggVIWUMgzHBNtnZ%2FDY%3D', 'questions': \"Explain the image and describe its contents in bullet points\"}\n",
    " \n",
    "url = \"https://logapp-mumhack.azurewebsites.net:443/api/aoaiimageanalysis/triggers/When_a_HTTP_request_is_received/invoke?api-version=2022-05-01&sp=%2Ftriggers%2FWhen_a_HTTP_request_is_received%2Frun&sv=1.0&sig=Trr2sP5IGDajGcmG-mqQ5YJ8z78sI18pgBRpQ9hISeg\"\n",
    "\n",
    "consume_api(url, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
